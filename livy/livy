#!/usr/bin/ruby
require 'net/http'
require 'json'
require 'optparse'

def parseOptions
	config_options = {
		:livy_home => "/usr/lib/livy",
		:cli => true,
		:log_dir => "/mnt/var/log/livy",
		:binary => "http://archive.cloudera.com/beta/livy/livy-server-0.3.0.zip"
	}

	opt_parser = OptionParser.new do |opt|
    	opt.banner = "Usage: livy-install [OPTIONS]"

   		opt.on("-d",'--home-dir [ Home Directory ]',
	           "Ex : /home/hadoop/ )") do |livy_home|
	      		config_options[:livy_home] = livy_home
	    end

	    opt.on("-l",'--log-dir [ Log Directory ]',
	           "Ex : /home/hadoop/ )") do |log_dir|
	      		config_options[:log_dir] = log_dir
	    end

	end
	opt_parser.parse!
	return config_options
end

@parsed = parseOptions
puts "Installing Livy 0.3.0"

def run(cmd)
  if ! system(cmd) then
    raise "Command failed: #{cmd}"
  end
end

def sudo(cmd)
  run("sudo #{cmd}")
end

def getClusterMetaData
	metaData = {}
	jobFlow = JSON.parse(File.read('/mnt/var/lib/info/job-flow.json'))
	userData = JSON.parse(Net::HTTP.get(URI('http://169.254.169.254/latest/user-data/')))

	#Determine if Instance Has IAM Roles
	req = Net::HTTP.get_response(URI('http://169.254.169.254/latest/meta-data/iam/security-credentials/'))
	metaData['roles'] = (req.code.to_i == 200) ? true : false

	metaData['instanceId'] = Net::HTTP.get(URI('http://169.254.169.254/latest/meta-data/instance-id/'))
	metaData['instanceType'] = Net::HTTP.get(URI('http://169.254.169.254/latest/meta-data/instance-type/'))
	metaData['masterPrivateDnsName'] = jobFlow['masterPrivateDnsName']
	metaData['isMaster'] = userData['isMaster']
	metaData['publicHostname'] = Net::HTTP.get(URI('http://169.254.169.254/latest/meta-data/public-hostname'))

	return metaData
end

clusterMetaData = getClusterMetaData

if clusterMetaData['isMaster'] == false
	exit 0
end

def setLivyConfig(metaData,parsed)
	config = []
	config << "livy.spark.deployMode = cluster"
	config << "livy.spark.master = yarn"
	config << "livy.rsc.rpc.server.address = #{metaData['publicHostname']}"

	return config.join("\n")
end


puts "Downloading the Binary Package"
run "mkdir -p /mnt/tmp/"
run "sudo mkdir -p #{@parsed[:livy_home]}"
run "sudo chown -R hadoop:hadoop #{@parsed[:livy_home]}"
run "wget -S -T 10 -t 5 \"#{@parsed[:binary]}\" -O /mnt/tmp/livy-server-0.3.0.zip"
run "unzip /mnt/tmp/livy-server-0.3.0.zip -d #{@parsed[:livy_home]}"
run "mv #{@parsed[:livy_home]}/livy-server-0.3.0/* #{@parsed[:livy_home]}/"
run "sudo chmod gau+x #{@parsed[:livy_home]}/*"

#Make the LogDir
sudo "mkdir -p #{@parsed[:log_dir]}"
sudo "chown -R hadoop:hadoop #{@parsed[:log_dir]}"

def configLivyEnv(clusterMetaData,parsed)
	config = "
    export SPARK_HOME=/usr/lib/spark
    export HADOOP_CONF_DIR=/etc/hadoop/conf
	export LIVY_LOG_DIR=#{@parsed[:log_dir]}
	export LIVY_PID_DIR=#{@parsed[:log_dir]}
    "
	return config
end

#Set livy-env.sh
open("#{@parsed[:livy_home]}/conf/livy-env.sh", 'w') do |f|
  	f.puts(configLivyEnv(clusterMetaData,@parsed))
end


def configServiceLogPusher
	livy = {
  		"/mnt/var/log/livy" : {
    		"includes" : [ "(.*)" ],
			"excludes" : [ "(.pid)" ],
    		"s3Path" : "node/$instance-id/applications/livy/$0",
    		"retentionPeriod" : "2d",
    		"logType" : [ "USER_LOG", "SYSTEM_LOG" ]
  		}
	}

	return livy
end



def configServiceNannyMaster
	snConfig = []

	livy = {
		"name" => "livy",
    	"type" => "process",
    	"pid-file" => "#{@parsed[:log_dir]}/livy-hadoop-server.pid",
    	"start" => "/etc/init.d/livy start",
    	"stop" => "/etc/init.d/livy stop",
   		"pattern" => "livy"
	}

	snConfig << livy

	return snConfig
end


def configInitD()
	config = "
. /lib/lsb/init-functions

PID_FILE=/mnt/var/log/livy/livy-hadoop-server.pid

function start {

   echo \"(console) $(date '+%Y-%m-%d %H:%M:%S')   listing currently running livys: \" > /dev/console
   ps -efww | grep -i livy > /dev/console
   echo \"(console) $(date '+%Y-%m-%d %H:%M:%S')  Displaying last 100 lines of livy logfile: \" > /dev/console
   tail -n 100 /mnt/var/log/livy/livy--server.log > /dev/console

   mkdir -p `dirname ${PID_FILE}`

   su hadoop -c "/sbin/start-stop-daemon --start \
       --exec /usr/lib/livy/bin/livy-server start \
       --pidfile $PID_FILE \
       --verbose"
}

function stop {
   echo \"(console) $(date '+%Y-%m-%d %H:%M:%S') Livy stop called!\" > /dev/console
   su hadoop -c "/sbin/start-stop-daemon --stop --pidfile $PID_FILE --verbose"
}

function reload {
    echo \"(console) $(date '+%Y-%m-%d %H:%M:%S') Livy restart called!\" > /dev/console
    stop
    start
}

function status {
    if [ -e $PID_FILE ] && ps --pid $(cat $PID_FILE) > /dev/null 2>&1 ; then
      log_success_msg \"Running\"
      exit 0
    else
      log_warning_msg \"Not Running\"
      exit 3
    fi
}

case $1 in
    'start' )
        start
        ;;
    'stop' )
        stop
        ;;
    'restart' )
        stop
        start
        ;;
    'force-reload' )
        reload
        ;;
    'status' )
        status
        ;;
    *)
        echo \"usage: `basename $0` {start|stop|status}\"
esac

exit 0
    "
	return config
end


#Set Livy conf
open("#{@parsed[:livy_home]}/conf/livy.conf", 'w') do |f|
  	f.puts(setLivyConfig(clusterMetaData,@parsed))
end

#Set Logpusher Settings
conf = JSON.generate(configServiceLogPusher)
open("/tmp/livy.config", 'w') do |f|
  	f.puts(conf)
end
sudo "cp /tmp/livy.config /etc/logpusher/livy.config"

#Set Service-Nanny

if clusterMetaData['isMaster'] == true
	conf = JSON.generate(configServiceNannyMaster)
end
open("/tmp/sn-livy.conf", 'w') do |f|
  	f.puts(conf)
end
sudo "cp /tmp/sn-livy.conf /etc/service-nanny/livy.conf"

#Set init.d
open("/tmp/initd-livy", 'w') do |f|
  	f.puts(configInitD())
end
sudo "cp /tmp/initd-livy /etc/init.d/livy"
sudo "chmod gau+x /etc/init.d/livy"

#Restart IC and SN
def reloadServiceNanny
  puts "restart service-nanny"
  if File.exists?('/mnt/var/run/service-nanny/service-nanny.pid')
    sudo '/etc/init.d/service-nanny restart'
  else
    sudo '/etc/init.d/service-nanny start'
  end
end

reloadServiceNanny
puts "Livy Install Finished"
exit 0