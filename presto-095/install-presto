#!/usr/bin/ruby
require 'net/http'
require 'json'
require 'optparse'


def parseOptions
	config_options = {
		:port => 9083,
		:presto_home => "/home/hadoop/.versions/presto-server-0.95/",
	}

	opt_parser = OptionParser.new do |opt|
    	opt.banner = "Usage: presto-install [OPTIONS]"

   		opt.on("-d",'--home-dir [ Home Directory ]',
	           "Ex : /home/hadoop/.versions/presto-server-0.95/ )") do |presto_home|
	      		config_options[:presto_home] = presto_home
	    end

	    opt.on("-p",'--hive-port [ Hive Metastore Port ]',
	           "Ex : 9083 )") do |port|
	      		config_options[:port] = port
	    end

		opt.on("-m",'--MaxMemory [ Memory Specified in Java -Xmx Formatting ]',
	           "Ex : 512M )") do |xmx_value|
	      		config_options[:xmx] = xmx_value
	    end

	    opt.on("-n",'--NurseryMem [ Nursery Memory Specified in Java -Xmn Formatting ]',
	           "Ex : 512M )") do |nurse|
	      		config_options[:nurse] = nurse
	    end

	    opt.on("-v",'--version [ Version of Presto to Install. For Future Use, not currently active ]',
	           "Ex : 0.95 )") do |version|
	      		config_options[:version] = version
	    end

	    opt.on('-h', '--help', 'Display this message') do
	      puts opt
	      exit
	    end

	end
	opt_parser.parse!
	return config_options
end

@parsed = parseOptions
@presto_home = @parsed[:presto_home]

puts "Installing Presto With Java 1.8 Requirement"

def run(cmd)
  if ! system(cmd) then
    raise "Command failed: #{cmd}"
  end
end

def sudo(cmd)
  run("sudo #{cmd}")
end

#First Install Java-1.8. If this is not present, nothing else will matter.
begin
	sudo "yum install java-1.8.0-openjdk-headless.x86_64 -y"
rescue
	puts "Failed to install Java 1.8, killing BA"
	puts $!, $@
	exit 1
end

def getClusterMetaData
	metaData = {}
	jobFlow = JSON.parse(File.read('/mnt/var/lib/info/job-flow.json'))
	userData = JSON.parse(Net::HTTP.get(URI('http://169.254.169.254/latest/user-data/')))


	metaData['instanceId'] = Net::HTTP.get(URI('http://169.254.169.254/latest/meta-data/instance-id/'))
	metaData['instanceType'] = Net::HTTP.get(URI('http://169.254.169.254/latest/meta-data/instance-type/'))
	metaData['masterPrivateDnsName'] = jobFlow['masterPrivateDnsName']
	metaData['isMaster'] = userData['isMaster']

	return metaData
end

def determineMemory(type,parsed)
	memory = {}	

	if type.include? 'small'
		memory['max'] = 512
		memory['nurse'] = 256
	elsif type.include? 'medium'
		memory['max'] = 1024
		memory['nurse'] = 512
	elsif type.include? 'large'
		memory['max'] = 2048
		memory['nurse'] = 512
	elsif type.include? 'xlarge'
		memory['max'] = 4096
		memory['nurse'] = 512
	end

	if parsed[:xmx]
		memory['max'] = parsed[:xmx]
	end

	if parsed[:nurse]
		memory['nurse'] = parsed[:nurse]
	end

	return memory
end

def setConfigProperties(metaData)
	config = []
	memory = determineMemory(metaData['instanceType'],@parsed)
	if metaData['isMaster'] == true
		config << 'coordinator=true'
	else
		config << 'coordinator=false'
	end

	config << "discovery.uri=http://#{metaData['masterPrivateDnsName']}:8080"
    config << 'http-server.threads.max=500'
    config << 'discovery-server.enabled=true'
    config << 'sink.max-buffer-size=1GB'
    config << 'node-scheduler.include-coordinator=false'
    config << "task.max-memory=#{memory['max']}MB"
    config << 'query.max-history=40'
    config << 'query.max-age=30m'
    config << 'http-server.http.port=8080'

    return config.join("\n")
end

def setHiveProperties(metaData,parsed)
	config = []

	config << 'hive.s3.connect-timeout=2m'
	config << "hive.s3.max-backoff-time=10m"
	config << "hive.s3.max-error-retries=50"
	config << "hive.metastore-refresh-interval=1m"
	config << "hive.s3.max-connections=500"
	config << "hive.s3.max-client-retries=50"
	config << "connector.name=hive-hadoop2"
	config << "hive.s3.socket-timeout=2m"
	config << "hive.metastore.uri=thrift://#{metaData['masterPrivateDnsName']}:#{parsed[:port]}"
	config << "hive.metastore-cache-ttl=20m"
	config << "hive.s3.staging-directory=/mnt/tmp/"

	puts "Setting Hive Catalog With the Following Properties:"
	puts config.join(" , ")
	return config.join("\n")
end

def setJVMConfig(metaData)
	config = []
	memory = determineMemory(metaData['instanceType'],@parsed)

	config << '-verbose:class'
	config << '-server'
	config << "-Xmx#{memory['max']}M"
	config << "-Xmn#{memory['nurse']}M"
	config << "-XX:+UseConcMarkSweepGC"
	config << "-XX:+ExplicitGCInvokesConcurrent"
	config << "-XX:+CMSClassUnloadingEnabled"
	config << "-XX:+AggressiveOpts"
	config << "-XX:+HeapDumpOnOutOfMemoryError"
	config << "-XX:OnOutOfMemoryError=kill -9 %p"
	config << "-XX:ReservedCodeCacheSize=150M"
	config << "-Xbootclasspath/p:"
	config << "-Dhive.config.resources=/home/hadoop/conf/core-site.xml,/home/hadoop/conf/hdfs-site.xml"

	return config.join("\n")
end

def setNodeConfig(metaData)
	config = []

	config << "node.data-dir=/mnt/var/log/presto"
	config << "node.id=#{metaData['instanceId']}"
	config << "node.environment=production"

	return config.join("\n")
end

def configServiceNanny
	snConfig = []

	presto = {
		"name" => "presto-server",
    	"type" => "process",
    	"pid-file" => "/mnt/var/log/presto/var/run/launcher.pid",
    	"start" => "#{@presto_home}/bin/launcher start",
    	"stop" => "#{@presto_home}/bin/launcher stop",
   		"pattern" => "instance-controller"
	}

	snConfig << presto
	return snConfig
end

def configServiceIC
	icConfig = JSON.parse(File.read('/etc/instance-controller/logs.json'))
	presto = {
      	"delayPush" => "true",
      	"s3Path" => "node/$instance-id/apps/presto/$0",
      	"fileGlob" => "/mnt/var/log/presto/var/log/(.*)"
    }

    icConfig['logFileTypes'][1]['logFilePatterns'] << presto
	return icConfig
end

def buildCLIWrapper
	config = []

	config << "#!/bin/bash"
	config << "export PATH=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.31-2.b13.5.amzn1.x86_64/jre/bin/:$PATH"
	config << "#{@presto_home}/presto-cli-0.95-executable.jar $@"

	return config.join("\n")
end
	
# Get The Cluster Information Object
clusterMetaData = getClusterMetaData

#Now, Lets Fetch The Archives from S3
run "curl -kLo /tmp/presto-server.tar.gz http://s3.amazonaws.com/support.elasticmapreduce/bootstrap-actions/presto/0.95/presto-server-0-95.tar.gz"
run "curl -kLo /tmp/presto-cli-0.95-executable.jar http://s3.amazonaws.com/support.elasticmapreduce/bootstrap-actions/presto/0.95/presto-cli-0.95-executable.jar"

#Extract the Server to its new Home
run "mkdir -p #{@presto_home}"
run "tar -xf /tmp/presto-server.tar.gz -C #{@presto_home}"
run "cp /tmp/presto-cli-0.95-executable.jar #{@presto_home}"
run "chmod +x #{@presto_home}/presto-cli-0.95-executable.jar"

#Set config.properties
open("#{@presto_home}/etc/config.properties", 'w') do |f|
  	f.puts(setConfigProperties(clusterMetaData))
end

#Set jvm.config
open("#{@presto_home}/etc/jvm.config", 'w') do |f|
  	f.puts(setJVMConfig(clusterMetaData))
end

#Set Hive.config
open("#{@presto_home}/etc/catalog/hive.properties", 'w') do |f|
  	f.puts(setHiveProperties(clusterMetaData,@parsed))
end

#Set node.properties
open("#{@presto_home}/etc/node.properties", 'w') do |f|
  	f.puts(setNodeConfig(clusterMetaData))
end

#Set IC Settings
conf = JSON.generate(configServiceIC)
open("/tmp/ic-logs.json", 'w') do |f|
  	f.puts(conf)
end
`sudo cp /tmp/ic-logs.json /etc/instance-controller/logs.json`

#Set Service-Nanny
conf = JSON.generate(configServiceNanny)
open("/tmp/sn-presto.conf", 'w') do |f|
  	f.puts(conf)
end
sudo "cp /tmp/sn-presto.conf /etc/service-nanny/presto.conf"

#Create Presto Wrapper
if clusterMetaData['isMaster'] == true
	open("/home/hadoop/presto-cli", 'w') do |f|
	  	f.puts(buildCLIWrapper)
	end
	run "chmod +x /home/hadoop/presto-cli"
	sudo "ln -s /home/hadoop/presto-cli /usr/bin/"
end

#Set Symnlinkg For Presto to Home-Folder
if File.exist? "/home/hadoop/hive/bin/hive-init"
	run "rm -f home/hadoop/presto-server"
end
run "ln -s #{@presto_home} /home/hadoop/presto-server"

#Set The MetaStore
if clusterMetaData['isMaster'] == true


	if File.exist? "/home/hadoop/hive/bin/hive-init"
      File.open('/home/hadoop/hive/bin/hive-init', 'a') { |f|
        f.write("\n/home/hadoop/hive/bin/hive --service metastore -p #{@parsed[:port]} >> /mnt/var/log/apps/hive-metastore.log &\n")
      }
    end

	if File.exist? "/home/hadoop/hive/bin/mysqld-hiveserver-setup.sh"
        puts "mysqld-hiveserver-setup.sh exists therefore run hive-init"
        #correctMySqlScript
        # we dont have to run hive-init in later ami's, therefore, else would be triggerred in ami > 3.2.3 or 3.3.0
        run "sh /home/hadoop/hive/bin/hive-init"
      else
        run "sh /home/hadoop/hive/bin/hive-set-up.sh create_log_dirs"
        run "sh /home/hadoop/hive/bin/hive-set-up.sh setup_mysql"
        run "sh /home/hadoop/hive/bin/hive-set-up.sh setup_hive_server"
        run "sh /home/hadoop/hive/bin/init-hive-dfs.sh &"
        run "/home/hadoop/hive/bin/hive --service metastore -p #{@parsed[:port]} >> /mnt/var/log/apps/hive-metastore.log &"
      end

end
	

#Restart IC and SN
def reloadServiceNanny
  puts "restart service-nanny"
  if File.exists?('/mnt/var/run/service-nanny/service-nanny.pid')
    sudo '/etc/init.d/service-nanny restart'
  else
    sudo '/etc/init.d/service-nanny start'
  end
end


def reloadIC
  puts "restart instance-controller"
  if File.exists?('/mnt/var/run/instance-controller/instance-controller.pid')
    sudo '/etc/init.d/instance-controller restart'
  else
    sudo '/etc/init.d/instance-controller start'
  end
end
#sudo "/etc/init.d/service-nanny stop"
#sudo "/etc/init.d/service-nanny start"

#sudo "/etc/init.d/instance-controller stop"
#sudo "/etc/init.d/instance-controller start"
reloadServiceNanny
#reloadIC
puts "If Nothing Went Wrong, You should now have a Latest Version of Presto Installed"

exit 0


